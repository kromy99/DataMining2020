{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment: Spam Classification\n",
    "\n",
    "## Task: Detect Spam in SMS messages   \n",
    "\n",
    "Kaggle challenge: https://www.kaggle.com/uciml/sms-spam-collection-dataset\n",
    "\n",
    "### Problem description\n",
    "**Context**\n",
    "The SMS Spam Collection is a set of SMS tagged messages that have been collected for SMS Spam research. It contains one set of SMS messages in English of 5,574 messages, tagged acording being ham (legitimate) or spam.\n",
    "\n",
    "## Data\n",
    "The files contain one message per line. Each line is composed by two columns: v1 contains the label (ham or spam) and v2 contains the raw text.\n",
    "\n",
    "This corpus has been collected from free or free for research sources at the Internet.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1: Problem Statement\n",
    "Discuss the problem setting and the first implications of the given data set... \n",
    "* What assumptions can we make about the data?\n",
    "* What problems are we expecting?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2: First Data Analysis and Cleaning\n",
    "* Import the data to a Pandas DataFrame\n",
    "* Run first simple statistics and visualizations\n",
    "* Is there a need to clean the data? If yes, do so...\n",
    "\n",
    "see: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('spam.csv' , encoding = \"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop([\"Unnamed: 2\", \"Unnamed: 3\", \"Unnamed: 4\"], axis=1)\n",
    "data.head()\n",
    "data.columns =['label','body']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3: Feature Extraction\n",
    "## Hint : see lecture of week 6\n",
    "* How can we handle text?\n",
    "* Discuss possible features for a numerical repressentation!\n",
    "* How can we obtain a compact and non-sparse representation?\n",
    "\n",
    "See: https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html#sklearn.feature_extraction.text.CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import nltk\n",
    "#nltk.download('stopwords')\n",
    "stopwords= nltk.corpus.stopwords.words('english')\n",
    "\n",
    "def clean(sentence):\n",
    "    s = \"\".join(x for x in sentence if x not in string.punctuation)\n",
    "    temp = s.lower().split(' ')\n",
    "    temp2 = [x for x in temp if x not in stopwords]\n",
    "    return temp2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', '\\rham', '0', '008704050406', '0089my', '0121', '01223585236', '01223585334', '0125698789', '02', '020603', '0207', '02070836089', '02072069400', '02073162414', '02085076972', '020903', '021', '050703', '0578', '06', '060505', '061104', '07008009200', '07046744435', '07090201529', '07090298926', '07099833605', '071104', '07123456789', '0721072', '07732584351', '07734396839', '07742676969', '07753741225', '0776xxxxxxx', '07786200117', '077xxx', '078', '07801543489', '07808', '07808247860', '07808726822', '07815296484', '07821230901', '0784987', '0789xxxxxxx', '0794674629107880867867', '0796xxxxxx', '07973788240', '07xxxxxxxxx', '0800', '08000407165', '08000776320', '08000839402', '08000930705', '08000938767', '08001950382', '08002888812', '08002986030', '08002986906', '08002988890', '08006344447', '0808', '08081263000', '08081560665', '0825', '0844', '08448350055', '08448714184', '0845', '08450542832', '08452810071', '08452810073', '08452810075over18s', '0870', '08700621170150p', '08701213186', '08701237397', '08701417012', '08701417012150p', '0870141701216', '087016248', '08701752560', '087018728737', '0870241182716', '08702490080', '08702840625', '08702840625comuk', '08704439680', '08704439680tscs', '08706091795', '0870737910216yrs', '08707500020', '08707509020', '0870753331018', '08707808226', '08708034412', '08708800282', '08709222922']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vect = TfidfVectorizer(analyzer=clean)\n",
    "vector_output = vect.fit_transform(data['body'])\n",
    "\n",
    "print(vect.get_feature_names()[0:100])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "data['len'] = data['body'].apply(lambda x : len(x) - x.count(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['long_number'] = data['body'].apply(lambda x : len(re.findall('\\d{7,}',x)))\n",
    "data['short_number'] = data['body'].apply(lambda x : len(re.findall('\\d{4,6}',x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "def count_punct (text):\n",
    "    count = sum([1 for x in text if x in string.punctuation])\n",
    "    pp = round(100*count/(len(text)-text.count(\" \")),3)\n",
    "    return pp\n",
    "\n",
    "data['punct'] = data['body'].apply(lambda x : count_punct(x))\n",
    "\n",
    "testlink = \"hello buddwwy http how com are you.co ww ww.\"\n",
    "\n",
    "def  website (text):\n",
    "    if (len(re.findall('www|http|com|\\.co',text))>0):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "data['website'] = data['body'].apply(lambda x : website(x))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4: Train a Random Forrest Model\n",
    "* Train and evaluate the model using the approach from task 3\n",
    "* Diskuss the results -> possible improovements?\n",
    "* Use RF feature importance to see which features are driving the RF Decission\n",
    "\n",
    "See: https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_features = pd.concat([data['len'],data['long_number'],data['short_number'],data['punct'],data['website'],pd.DataFrame(vector_output.toarray())],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_features,data['label'])\n",
    "rf = RandomForestClassifier(n_estimators=2000,max_depth=None,n_jobs=-1)\n",
    "rf_model = rf.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision : 1.0 / Recall : 0.85492 / fscore : 0.92179 / Accuracy: 0.9799\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "y_pred=rf_model.predict(x_test)\n",
    "precision,recall,fscore,support =score(y_test,y_pred,pos_label='spam', average ='binary')\n",
    "print('Precision : {} / Recall : {} / fscore : {} / Accuracy: {}'.format(round(precision,5),round(recall,5),round(fscore,5),round((y_pred==y_test).sum()/len(y_test),5)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
